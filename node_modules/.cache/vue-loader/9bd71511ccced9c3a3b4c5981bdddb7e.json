{"remainingRequest":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\node_modules\\vue-loader\\lib\\index.js??vue-loader-options!C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\src\\views\\VideoMediaCanvasStream.vue?vue&type=script&lang=js&","dependencies":[{"path":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\src\\views\\VideoMediaCanvasStream.vue","mtime":1558766770000},{"path":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\node_modules\\cache-loader\\dist\\cjs.js","mtime":499162500000},{"path":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\node_modules\\babel-loader\\lib\\index.js","mtime":499162500000},{"path":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\node_modules\\cache-loader\\dist\\cjs.js","mtime":499162500000},{"path":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\node_modules\\vue-loader\\lib\\index.js","mtime":499162500000}],"contextDependencies":[],"result":["//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n\nimport * as faceapi from \"face-api.js\";\n\nexport default {\n  name: \"VideoMediaCanvasStream\",\n  data() {\n    return {\n      videoEl: {},\n      canvasEL: {},\n      facingMode: false,\n      userMediaConstraints: {\n        audio: false,\n        video: {\n          // ideal（应用最理想的）\n          width: {\n            min: 320,\n            ideal: 1280,\n            max: 1920\n          },\n          height: {\n            min: 240,\n            ideal: 720,\n            max: 1080\n          },\n          // frameRate受限带宽传输时，低帧率可能更适宜\n          frameRate: {\n            min: 15,\n            ideal: 30,\n            max: 60\n          },\n          // 摄像头翻转\n          facingMode: this.facingMode ? \"user\" : \"environment\"\n        }\n      },\n      timeInterval: 0,\n      failCount: 0\n    };\n  },\n  created() {\n    this.init();\n  },\n  methods: {\n    // 初始化\n    async init() {\n      // 加载模型\n      await faceapi.loadTinyFaceDetectorModel(\"/models\");\n      // dom元素\n      this.videoEl = this.$refs.videoDom;\n      this.canvasEL = this.$refs.canvasDOM;\n      // 启动WebRTC驱动摄像头视频媒体\n      await navigator.mediaDevices\n        .getUserMedia(this.userMediaConstraints)\n        .then(this.getMediaStreamSuccess)\n        .catch(this.getMediaStreamError);\n      // 启动检测\n      await this.onPlay();\n    },\n    // 视频绘制图像框\n    async onPlay() {\n      // 时间计时\n      const ts = Date.now();\n      // 判断视频对象是否暂停结束\n      if (this.videoEl.paused || this.videoEl.ended) {\n        this.timeInterval = setInterval(() => this.onPlay());\n        return;\n      }\n      // 简单人脸检测扫描\n      const faceDetectionTask = await faceapi.detectSingleFace(\n        this.videoEl,\n        new faceapi.TinyFaceDetectorOptions({\n          inputSize: 512,\n          scoreThreshold: 0.5\n        })\n      );\n      // 判断人脸扫描结果\n      if (faceDetectionTask) {\n        this.failCount = 0;\n        // 画布绘制人脸框\n        this.drawDetections(this.videoEl, this.canvasEL, [faceDetectionTask]);\n      } else {\n        this.failCount += 1;\n        if (this.failCount > 20) {\n          this.canvasEL.width = this.videoEl.videoWidth;\n          this.canvasEL.height = this.videoEl.videoHeight;\n          // 画布绘制\n          const ctx = this.canvasEL.getContext(\"2d\");\n          const linearGradient = ctx.createLinearGradient(0, 0, 300, 0);\n          linearGradient.addColorStop(\"0\", \"#40E0D0\");\n          linearGradient.addColorStop(\"0.5\", \"#FF8C00\");\n          linearGradient.addColorStop(\"1.0\", \"#FF0080\");\n          // 绘制信息\n          ctx.font = \"35px FZShuTi\";\n          ctx.fillStyle = linearGradient;\n          ctx.fillText(\"请将进入检测区\", 20, 50);\n        }\n        console.log(this.failCount, \"检测失败\");\n      }\n      // 绘制刷新状态\n      const runTime = {\n        time: Math.round(Date.now() - ts),\n        fps: faceapi.round(1000 / (Date.now() - ts))\n      };\n      // 绘制时间\n      console.log(\"绘制时间:\", runTime);\n    },\n    // 人脸框绘制\n    drawDetections(dimensions, canvas, detections) {\n      // 初始画布大小\n      canvas.width = dimensions.videoWidth;\n      canvas.height = dimensions.videoHeight;\n      // 视频对象人脸框在画布中绘制\n      detections.forEach(det => {\n        const { x, y, width, height } = det.box;\n        const ctx = canvas.getContext(\"2d\");\n        ctx.strokeStyle = \"red\";\n        ctx.lineWidth = 4;\n        ctx.strokeRect(x, y, width, height);\n      });\n    },\n    // 视频媒体流成功\n    getMediaStreamSuccess(stream) {\n      window.stream = stream; // make stream available to browser console\n      this.videoEl.srcObject = stream;\n    },\n    // 视频媒体流失败\n    getMediaStreamError(error) {\n      alert(\"视频媒体流获取错误\" + error);\n    },\n    // 结束媒体流\n    stopMediaStreamTrack() {\n      clearInterval(this.timeInterval);\n      if (typeof window.stream === \"object\") {\n        this.videoEl.srcObject = null;\n        window.stream.getTracks().forEach(track => track.stop());\n      }\n    }\n  },\n  beforeDestroy() {\n    this.stopMediaStreamTrack();\n  }\n};\n",{"version":3,"sources":["VideoMediaCanvasStream.vue"],"names":[],"mappings":";;;;;;;;;;;;;;AAcA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"VideoMediaCanvasStream.vue","sourceRoot":"src/views","sourcesContent":["<template>\n  <div class=\"media\">\n    <video\n      class=\"media-video\"\n      poster=\"https://ss0.bdstatic.com/94oJfD_bAAcT8t7mm9GUKT-xh_/timg?image&quality=100&size=b4000_4000&sec=1558759758&di=ccd0b08f63f2b6ea3ca08b651c4fa5f1&src=http://b-ssl.duitang.com/uploads/item/201610/05/20161005105402_xiLsK.thumb.700_0.jpeg\"\n      ref=\"videoDom\"\n      playsinline\n      autoplay\n    ></video>\n    <canvas class=\"media-canvas\" ref=\"canvasDOM\"></canvas>\n  </div>\n</template>\n\n<script>\nimport * as faceapi from \"face-api.js\";\n\nexport default {\n  name: \"VideoMediaCanvasStream\",\n  data() {\n    return {\n      videoEl: {},\n      canvasEL: {},\n      facingMode: false,\n      userMediaConstraints: {\n        audio: false,\n        video: {\n          // ideal（应用最理想的）\n          width: {\n            min: 320,\n            ideal: 1280,\n            max: 1920\n          },\n          height: {\n            min: 240,\n            ideal: 720,\n            max: 1080\n          },\n          // frameRate受限带宽传输时，低帧率可能更适宜\n          frameRate: {\n            min: 15,\n            ideal: 30,\n            max: 60\n          },\n          // 摄像头翻转\n          facingMode: this.facingMode ? \"user\" : \"environment\"\n        }\n      },\n      timeInterval: 0,\n      failCount: 0\n    };\n  },\n  created() {\n    this.init();\n  },\n  methods: {\n    // 初始化\n    async init() {\n      // 加载模型\n      await faceapi.loadTinyFaceDetectorModel(\"/models\");\n      // dom元素\n      this.videoEl = this.$refs.videoDom;\n      this.canvasEL = this.$refs.canvasDOM;\n      // 启动WebRTC驱动摄像头视频媒体\n      await navigator.mediaDevices\n        .getUserMedia(this.userMediaConstraints)\n        .then(this.getMediaStreamSuccess)\n        .catch(this.getMediaStreamError);\n      // 启动检测\n      await this.onPlay();\n    },\n    // 视频绘制图像框\n    async onPlay() {\n      // 时间计时\n      const ts = Date.now();\n      // 判断视频对象是否暂停结束\n      if (this.videoEl.paused || this.videoEl.ended) {\n        this.timeInterval = setInterval(() => this.onPlay());\n        return;\n      }\n      // 简单人脸检测扫描\n      const faceDetectionTask = await faceapi.detectSingleFace(\n        this.videoEl,\n        new faceapi.TinyFaceDetectorOptions({\n          inputSize: 512,\n          scoreThreshold: 0.5\n        })\n      );\n      // 判断人脸扫描结果\n      if (faceDetectionTask) {\n        this.failCount = 0;\n        // 画布绘制人脸框\n        this.drawDetections(this.videoEl, this.canvasEL, [faceDetectionTask]);\n      } else {\n        this.failCount += 1;\n        if (this.failCount > 20) {\n          this.canvasEL.width = this.videoEl.videoWidth;\n          this.canvasEL.height = this.videoEl.videoHeight;\n          // 画布绘制\n          const ctx = this.canvasEL.getContext(\"2d\");\n          const linearGradient = ctx.createLinearGradient(0, 0, 300, 0);\n          linearGradient.addColorStop(\"0\", \"#40E0D0\");\n          linearGradient.addColorStop(\"0.5\", \"#FF8C00\");\n          linearGradient.addColorStop(\"1.0\", \"#FF0080\");\n          // 绘制信息\n          ctx.font = \"35px FZShuTi\";\n          ctx.fillStyle = linearGradient;\n          ctx.fillText(\"请将进入检测区\", 20, 50);\n        }\n        console.log(this.failCount, \"检测失败\");\n      }\n      // 绘制刷新状态\n      const runTime = {\n        time: Math.round(Date.now() - ts),\n        fps: faceapi.round(1000 / (Date.now() - ts))\n      };\n      // 绘制时间\n      console.log(\"绘制时间:\", runTime);\n    },\n    // 人脸框绘制\n    drawDetections(dimensions, canvas, detections) {\n      // 初始画布大小\n      canvas.width = dimensions.videoWidth;\n      canvas.height = dimensions.videoHeight;\n      // 视频对象人脸框在画布中绘制\n      detections.forEach(det => {\n        const { x, y, width, height } = det.box;\n        const ctx = canvas.getContext(\"2d\");\n        ctx.strokeStyle = \"red\";\n        ctx.lineWidth = 4;\n        ctx.strokeRect(x, y, width, height);\n      });\n    },\n    // 视频媒体流成功\n    getMediaStreamSuccess(stream) {\n      window.stream = stream; // make stream available to browser console\n      this.videoEl.srcObject = stream;\n    },\n    // 视频媒体流失败\n    getMediaStreamError(error) {\n      alert(\"视频媒体流获取错误\" + error);\n    },\n    // 结束媒体流\n    stopMediaStreamTrack() {\n      clearInterval(this.timeInterval);\n      if (typeof window.stream === \"object\") {\n        this.videoEl.srcObject = null;\n        window.stream.getTracks().forEach(track => track.stop());\n      }\n    }\n  },\n  beforeDestroy() {\n    this.stopMediaStreamTrack();\n  }\n};\n</script>\n\n<style scoped>\n.media {\n  position: relative;\n}\n.media-video {\n  max-height: 860px;\n  height: 100%;\n  width: 100%;\n  display: block;\n  background-color: #242424;\n}\n.media-canvas {\n  position: absolute;\n  left: 0;\n  top: 0;\n  height: 100%;\n  width: 100%;\n}\n</style>\n"]}]}