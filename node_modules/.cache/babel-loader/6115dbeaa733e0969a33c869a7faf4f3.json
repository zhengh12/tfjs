{"remainingRequest":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\node_modules\\babel-loader\\lib\\index.js!C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\node_modules\\eslint-loader\\index.js??ref--13-0!C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\src\\utils\\data.js","dependencies":[{"path":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\src\\utils\\data.js","mtime":1574068171759},{"path":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\node_modules\\cache-loader\\dist\\cjs.js","mtime":499162500000},{"path":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\node_modules\\babel-loader\\lib\\index.js","mtime":499162500000},{"path":"C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\node_modules\\eslint-loader\\index.js","mtime":499162500000}],"contextDependencies":[],"result":["import \"core-js/modules/es6.typed.uint8-array\";\nimport \"core-js/modules/web.dom.iterable\";\nimport \"core-js/modules/es6.string.iterator\";\nimport _slicedToArray from \"C:\\\\Users\\\\1\\\\Desktop\\\\tensorflowjs\\\\face-api-demo-vue-master\\\\node_modules\\\\@babel\\\\runtime-corejs2/helpers/esm/slicedToArray\";\nimport \"core-js/modules/es6.typed.float32-array\";\nimport \"regenerator-runtime/runtime\";\nimport _asyncToGenerator from \"C:\\\\Users\\\\1\\\\Desktop\\\\tensorflowjs\\\\face-api-demo-vue-master\\\\node_modules\\\\@babel\\\\runtime-corejs2/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"C:\\\\Users\\\\1\\\\Desktop\\\\tensorflowjs\\\\face-api-demo-vue-master\\\\node_modules\\\\@babel\\\\runtime-corejs2/helpers/esm/classCallCheck\";\nimport _createClass from \"C:\\\\Users\\\\1\\\\Desktop\\\\tensorflowjs\\\\face-api-demo-vue-master\\\\node_modules\\\\@babel\\\\runtime-corejs2/helpers/esm/createClass\";\n\nvar tf = require(\"@tensorflow/tfjs\");\n\nvar IMAGE_SIZE = 784;\nvar NUM_CLASSES = 10;\nvar NUM_DATASET_ELEMENTS = 65000;\nvar NUM_TRAIN_ELEMENTS = 55000;\nvar NUM_TEST_ELEMENTS = NUM_DATASET_ELEMENTS - NUM_TRAIN_ELEMENTS;\nvar MNIST_IMAGES_SPRITE_PATH = 'https://storage.googleapis.com/learnjs-data/model-builder/mnist_images.png';\nvar MNIST_LABELS_PATH = 'https://storage.googleapis.com/learnjs-data/model-builder/mnist_labels_uint8';\n/**\r\n * A class that fetches the sprited MNIST dataset and returns shuffled batches.\r\n *\r\n * NOTE: This will get much easier. For now, we do data fetching and\r\n * manipulation manually.\r\n */\n\nexport var MnistData =\n/*#__PURE__*/\nfunction () {\n  function MnistData() {\n    _classCallCheck(this, MnistData);\n\n    this.shuffledTrainIndex = 0;\n    this.shuffledTestIndex = 0;\n    this.trainIndices = null;\n  }\n\n  _createClass(MnistData, [{\n    key: \"load\",\n    value: function () {\n      var _load = _asyncToGenerator(\n      /*#__PURE__*/\n      regeneratorRuntime.mark(function _callee() {\n        var _this = this;\n\n        var img, canvas, ctx, imgRequest, labelsRequest, _ref, _ref2, imgResponse, labelsResponse;\n\n        return regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                // Make a request for the MNIST sprited image.\n                img = new Image();\n                canvas = document.createElement('canvas');\n                ctx = canvas.getContext('2d');\n                imgRequest = new Promise(function (resolve, reject) {\n                  img.crossOrigin = '';\n\n                  img.onload = function () {\n                    img.width = img.naturalWidth;\n                    img.height = img.naturalHeight;\n                    var datasetBytesBuffer = new ArrayBuffer(NUM_DATASET_ELEMENTS * IMAGE_SIZE * 4);\n                    var chunkSize = 5000;\n                    canvas.width = img.width;\n                    canvas.height = chunkSize;\n\n                    for (var i = 0; i < NUM_DATASET_ELEMENTS / chunkSize; i++) {\n                      var datasetBytesView = new Float32Array(datasetBytesBuffer, i * IMAGE_SIZE * chunkSize * 4, IMAGE_SIZE * chunkSize);\n                      ctx.drawImage(img, 0, i * chunkSize, img.width, chunkSize, 0, 0, img.width, chunkSize);\n                      var imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n\n                      for (var j = 0; j < imageData.data.length / 4; j++) {\n                        // All channels hold an equal value since the image is grayscale, so\n                        // just read the red channel.\n                        datasetBytesView[j] = imageData.data[j * 4] / 255;\n                      }\n                    }\n\n                    _this.datasetImages = new Float32Array(datasetBytesBuffer);\n                    resolve();\n                  };\n\n                  img.src = MNIST_IMAGES_SPRITE_PATH;\n                });\n                labelsRequest = fetch(MNIST_LABELS_PATH);\n                _context.next = 7;\n                return Promise.all([imgRequest, labelsRequest]);\n\n              case 7:\n                _ref = _context.sent;\n                _ref2 = _slicedToArray(_ref, 2);\n                imgResponse = _ref2[0];\n                labelsResponse = _ref2[1];\n                _context.t0 = Uint8Array;\n                _context.next = 14;\n                return labelsResponse.arrayBuffer();\n\n              case 14:\n                _context.t1 = _context.sent;\n                this.datasetLabels = new _context.t0(_context.t1);\n                // Create shuffled indices into the train/test set for when we select a\n                // random dataset element for training / validation.\n                this.trainIndices = tf.util.createShuffledIndices(NUM_TRAIN_ELEMENTS);\n                this.testIndices = tf.util.createShuffledIndices(NUM_TEST_ELEMENTS); // Slice the the images and labels into train and test sets.\n\n                this.trainImages = this.datasetImages.slice(0, IMAGE_SIZE * NUM_TRAIN_ELEMENTS);\n                this.testImages = this.datasetImages.slice(IMAGE_SIZE * NUM_TRAIN_ELEMENTS);\n                this.trainLabels = this.datasetLabels.slice(0, NUM_CLASSES * NUM_TRAIN_ELEMENTS);\n                this.testLabels = this.datasetLabels.slice(NUM_CLASSES * NUM_TRAIN_ELEMENTS);\n\n              case 22:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function load() {\n        return _load.apply(this, arguments);\n      }\n\n      return load;\n    }()\n  }, {\n    key: \"nextTrainBatch\",\n    value: function nextTrainBatch(batchSize) {\n      var _this2 = this;\n\n      return this.nextBatch(batchSize, [this.trainImages, this.trainLabels], function () {\n        _this2.shuffledTrainIndex = (_this2.shuffledTrainIndex + 1) % _this2.trainIndices.length;\n        return _this2.trainIndices[_this2.shuffledTrainIndex];\n      });\n    }\n  }, {\n    key: \"nextTestBatch\",\n    value: function nextTestBatch(batchSize) {\n      var _this3 = this;\n\n      return this.nextBatch(batchSize, [this.testImages, this.testLabels], function () {\n        _this3.shuffledTestIndex = (_this3.shuffledTestIndex + 1) % _this3.testIndices.length;\n        return _this3.testIndices[_this3.shuffledTestIndex];\n      });\n    }\n  }, {\n    key: \"nextBatch\",\n    value: function nextBatch(batchSize, data, index) {\n      var batchImagesArray = new Float32Array(batchSize * IMAGE_SIZE);\n      var batchLabelsArray = new Uint8Array(batchSize * NUM_CLASSES);\n\n      for (var i = 0; i < batchSize; i++) {\n        var idx = index();\n        var image = data[0].slice(idx * IMAGE_SIZE, idx * IMAGE_SIZE + IMAGE_SIZE);\n        batchImagesArray.set(image, i * IMAGE_SIZE);\n        var label = data[1].slice(idx * NUM_CLASSES, idx * NUM_CLASSES + NUM_CLASSES);\n        batchLabelsArray.set(label, i * NUM_CLASSES);\n      }\n\n      var xs = tf.tensor2d(batchImagesArray, [batchSize, IMAGE_SIZE]);\n      var labels = tf.tensor2d(batchLabelsArray, [batchSize, NUM_CLASSES]);\n      return {\n        xs: xs,\n        labels: labels\n      };\n    }\n  }]);\n\n  return MnistData;\n}();\nexport default MnistData;",{"version":3,"sources":["C:\\Users\\1\\Desktop\\tensorflowjs\\face-api-demo-vue-master\\src\\utils\\data.js"],"names":["tf","require","IMAGE_SIZE","NUM_CLASSES","NUM_DATASET_ELEMENTS","NUM_TRAIN_ELEMENTS","NUM_TEST_ELEMENTS","MNIST_IMAGES_SPRITE_PATH","MNIST_LABELS_PATH","MnistData","shuffledTrainIndex","shuffledTestIndex","trainIndices","img","Image","canvas","document","createElement","ctx","getContext","imgRequest","Promise","resolve","reject","crossOrigin","onload","width","naturalWidth","height","naturalHeight","datasetBytesBuffer","ArrayBuffer","chunkSize","i","datasetBytesView","Float32Array","drawImage","imageData","getImageData","j","data","length","datasetImages","src","labelsRequest","fetch","all","imgResponse","labelsResponse","Uint8Array","arrayBuffer","datasetLabels","util","createShuffledIndices","testIndices","trainImages","slice","testImages","trainLabels","testLabels","batchSize","nextBatch","index","batchImagesArray","batchLabelsArray","idx","image","set","label","xs","tensor2d","labels"],"mappings":";;;;;;;;;;AAAA,IAAMA,EAAE,GAAGC,OAAO,CAAC,kBAAD,CAAlB;;AACA,IAAMC,UAAU,GAAG,GAAnB;AACA,IAAMC,WAAW,GAAG,EAApB;AACA,IAAMC,oBAAoB,GAAG,KAA7B;AAEA,IAAMC,kBAAkB,GAAG,KAA3B;AACA,IAAMC,iBAAiB,GAAGF,oBAAoB,GAAGC,kBAAjD;AAEA,IAAME,wBAAwB,GAC1B,4EADJ;AAEA,IAAMC,iBAAiB,GACnB,8EADJ;AAGA;;;;;;;AAMA,WAAaC,SAAb;AAAA;AAAA;AACE,uBAAc;AAAA;;AACZ,SAAKC,kBAAL,GAA0B,CAA1B;AACA,SAAKC,iBAAL,GAAyB,CAAzB;AACA,SAAKC,YAAL,GAAoB,IAApB;AACD;;AALH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;AAAA;AAAA;AAQI;AACMC,gBAAAA,GATV,GASgB,IAAIC,KAAJ,EAThB;AAUUC,gBAAAA,MAVV,GAUmBC,QAAQ,CAACC,aAAT,CAAuB,QAAvB,CAVnB;AAWUC,gBAAAA,GAXV,GAWgBH,MAAM,CAACI,UAAP,CAAkB,IAAlB,CAXhB;AAYUC,gBAAAA,UAZV,GAYuB,IAAIC,OAAJ,CAAY,UAACC,OAAD,EAAUC,MAAV,EAAqB;AAClDV,kBAAAA,GAAG,CAACW,WAAJ,GAAkB,EAAlB;;AACAX,kBAAAA,GAAG,CAACY,MAAJ,GAAa,YAAM;AACjBZ,oBAAAA,GAAG,CAACa,KAAJ,GAAYb,GAAG,CAACc,YAAhB;AACAd,oBAAAA,GAAG,CAACe,MAAJ,GAAaf,GAAG,CAACgB,aAAjB;AAEA,wBAAMC,kBAAkB,GACpB,IAAIC,WAAJ,CAAgB3B,oBAAoB,GAAGF,UAAvB,GAAoC,CAApD,CADJ;AAGA,wBAAM8B,SAAS,GAAG,IAAlB;AACAjB,oBAAAA,MAAM,CAACW,KAAP,GAAeb,GAAG,CAACa,KAAnB;AACAX,oBAAAA,MAAM,CAACa,MAAP,GAAgBI,SAAhB;;AAEA,yBAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG7B,oBAAoB,GAAG4B,SAA3C,EAAsDC,CAAC,EAAvD,EAA2D;AACzD,0BAAMC,gBAAgB,GAAG,IAAIC,YAAJ,CACrBL,kBADqB,EACDG,CAAC,GAAG/B,UAAJ,GAAiB8B,SAAjB,GAA6B,CAD5B,EAErB9B,UAAU,GAAG8B,SAFQ,CAAzB;AAGAd,sBAAAA,GAAG,CAACkB,SAAJ,CACIvB,GADJ,EACS,CADT,EACYoB,CAAC,GAAGD,SADhB,EAC2BnB,GAAG,CAACa,KAD/B,EACsCM,SADtC,EACiD,CADjD,EACoD,CADpD,EACuDnB,GAAG,CAACa,KAD3D,EAEIM,SAFJ;AAIA,0BAAMK,SAAS,GAAGnB,GAAG,CAACoB,YAAJ,CAAiB,CAAjB,EAAoB,CAApB,EAAuBvB,MAAM,CAACW,KAA9B,EAAqCX,MAAM,CAACa,MAA5C,CAAlB;;AAEA,2BAAK,IAAIW,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGF,SAAS,CAACG,IAAV,CAAeC,MAAf,GAAwB,CAA5C,EAA+CF,CAAC,EAAhD,EAAoD;AAClD;AACA;AACAL,wBAAAA,gBAAgB,CAACK,CAAD,CAAhB,GAAsBF,SAAS,CAACG,IAAV,CAAeD,CAAC,GAAG,CAAnB,IAAwB,GAA9C;AACD;AACF;;AACD,oBAAA,KAAI,CAACG,aAAL,GAAqB,IAAIP,YAAJ,CAAiBL,kBAAjB,CAArB;AAEAR,oBAAAA,OAAO;AACR,mBA9BD;;AA+BAT,kBAAAA,GAAG,CAAC8B,GAAJ,GAAUpC,wBAAV;AACD,iBAlCkB,CAZvB;AAgDUqC,gBAAAA,aAhDV,GAgD0BC,KAAK,CAACrC,iBAAD,CAhD/B;AAAA;AAAA,uBAkDca,OAAO,CAACyB,GAAR,CAAY,CAAC1B,UAAD,EAAawB,aAAb,CAAZ,CAlDd;;AAAA;AAAA;AAAA;AAiDWG,gBAAAA,WAjDX;AAiDwBC,gBAAAA,cAjDxB;AAAA,8BAoD6BC,UApD7B;AAAA;AAAA,uBAoD8CD,cAAc,CAACE,WAAf,EApD9C;;AAAA;AAAA;AAoDI,qBAAKC,aApDT;AAsDI;AACA;AACA,qBAAKvC,YAAL,GAAoBZ,EAAE,CAACoD,IAAH,CAAQC,qBAAR,CAA8BhD,kBAA9B,CAApB;AACA,qBAAKiD,WAAL,GAAmBtD,EAAE,CAACoD,IAAH,CAAQC,qBAAR,CAA8B/C,iBAA9B,CAAnB,CAzDJ,CA0DI;;AACA,qBAAKiD,WAAL,GACI,KAAKb,aAAL,CAAmBc,KAAnB,CAAyB,CAAzB,EAA4BtD,UAAU,GAAGG,kBAAzC,CADJ;AAEA,qBAAKoD,UAAL,GAAkB,KAAKf,aAAL,CAAmBc,KAAnB,CAAyBtD,UAAU,GAAGG,kBAAtC,CAAlB;AACA,qBAAKqD,WAAL,GACI,KAAKP,aAAL,CAAmBK,KAAnB,CAAyB,CAAzB,EAA4BrD,WAAW,GAAGE,kBAA1C,CADJ;AAEA,qBAAKsD,UAAL,GACI,KAAKR,aAAL,CAAmBK,KAAnB,CAAyBrD,WAAW,GAAGE,kBAAvC,CADJ;;AAhEJ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA,mCAoEiBuD,SApEjB,EAoE4B;AAAA;;AACxB,aAAO,KAAKC,SAAL,CACHD,SADG,EACQ,CAAC,KAAKL,WAAN,EAAmB,KAAKG,WAAxB,CADR,EAC8C,YAAM;AACrD,QAAA,MAAI,CAAChD,kBAAL,GACI,CAAC,MAAI,CAACA,kBAAL,GAA0B,CAA3B,IAAgC,MAAI,CAACE,YAAL,CAAkB6B,MADtD;AAEA,eAAO,MAAI,CAAC7B,YAAL,CAAkB,MAAI,CAACF,kBAAvB,CAAP;AACD,OALE,CAAP;AAMD;AA3EH;AAAA;AAAA,kCA6EgBkD,SA7EhB,EA6E2B;AAAA;;AACvB,aAAO,KAAKC,SAAL,CAAeD,SAAf,EAA0B,CAAC,KAAKH,UAAN,EAAkB,KAAKE,UAAvB,CAA1B,EAA8D,YAAM;AACzE,QAAA,MAAI,CAAChD,iBAAL,GACI,CAAC,MAAI,CAACA,iBAAL,GAAyB,CAA1B,IAA+B,MAAI,CAAC2C,WAAL,CAAiBb,MADpD;AAEA,eAAO,MAAI,CAACa,WAAL,CAAiB,MAAI,CAAC3C,iBAAtB,CAAP;AACD,OAJM,CAAP;AAKD;AAnFH;AAAA;AAAA,8BAqFYiD,SArFZ,EAqFuBpB,IArFvB,EAqF6BsB,KArF7B,EAqFoC;AAChC,UAAMC,gBAAgB,GAAG,IAAI5B,YAAJ,CAAiByB,SAAS,GAAG1D,UAA7B,CAAzB;AACA,UAAM8D,gBAAgB,GAAG,IAAIf,UAAJ,CAAeW,SAAS,GAAGzD,WAA3B,CAAzB;;AAEA,WAAK,IAAI8B,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG2B,SAApB,EAA+B3B,CAAC,EAAhC,EAAoC;AAClC,YAAMgC,GAAG,GAAGH,KAAK,EAAjB;AAEA,YAAMI,KAAK,GACP1B,IAAI,CAAC,CAAD,CAAJ,CAAQgB,KAAR,CAAcS,GAAG,GAAG/D,UAApB,EAAgC+D,GAAG,GAAG/D,UAAN,GAAmBA,UAAnD,CADJ;AAEA6D,QAAAA,gBAAgB,CAACI,GAAjB,CAAqBD,KAArB,EAA4BjC,CAAC,GAAG/B,UAAhC;AAEA,YAAMkE,KAAK,GACP5B,IAAI,CAAC,CAAD,CAAJ,CAAQgB,KAAR,CAAcS,GAAG,GAAG9D,WAApB,EAAiC8D,GAAG,GAAG9D,WAAN,GAAoBA,WAArD,CADJ;AAEA6D,QAAAA,gBAAgB,CAACG,GAAjB,CAAqBC,KAArB,EAA4BnC,CAAC,GAAG9B,WAAhC;AACD;;AAED,UAAMkE,EAAE,GAAGrE,EAAE,CAACsE,QAAH,CAAYP,gBAAZ,EAA8B,CAACH,SAAD,EAAY1D,UAAZ,CAA9B,CAAX;AACA,UAAMqE,MAAM,GAAGvE,EAAE,CAACsE,QAAH,CAAYN,gBAAZ,EAA8B,CAACJ,SAAD,EAAYzD,WAAZ,CAA9B,CAAf;AAEA,aAAO;AAACkE,QAAAA,EAAE,EAAFA,EAAD;AAAKE,QAAAA,MAAM,EAANA;AAAL,OAAP;AACD;AAzGH;;AAAA;AAAA;AA4GA,eAAe9D,SAAf","sourcesContent":["const tf = require(\"@tensorflow/tfjs\");\r\nconst IMAGE_SIZE = 784;\r\nconst NUM_CLASSES = 10;\r\nconst NUM_DATASET_ELEMENTS = 65000;\r\n\r\nconst NUM_TRAIN_ELEMENTS = 55000;\r\nconst NUM_TEST_ELEMENTS = NUM_DATASET_ELEMENTS - NUM_TRAIN_ELEMENTS;\r\n\r\nconst MNIST_IMAGES_SPRITE_PATH =\r\n    'https://storage.googleapis.com/learnjs-data/model-builder/mnist_images.png';\r\nconst MNIST_LABELS_PATH =\r\n    'https://storage.googleapis.com/learnjs-data/model-builder/mnist_labels_uint8';\r\n\r\n/**\r\n * A class that fetches the sprited MNIST dataset and returns shuffled batches.\r\n *\r\n * NOTE: This will get much easier. For now, we do data fetching and\r\n * manipulation manually.\r\n */\r\nexport class MnistData {\r\n  constructor() {\r\n    this.shuffledTrainIndex = 0;\r\n    this.shuffledTestIndex = 0;\r\n    this.trainIndices = null\r\n  }\r\n\r\n  async load() {\r\n    // Make a request for the MNIST sprited image.\r\n    const img = new Image();\r\n    const canvas = document.createElement('canvas');\r\n    const ctx = canvas.getContext('2d');\r\n    const imgRequest = new Promise((resolve, reject) => {\r\n      img.crossOrigin = '';\r\n      img.onload = () => {\r\n        img.width = img.naturalWidth;\r\n        img.height = img.naturalHeight;\r\n\r\n        const datasetBytesBuffer =\r\n            new ArrayBuffer(NUM_DATASET_ELEMENTS * IMAGE_SIZE * 4);\r\n\r\n        const chunkSize = 5000;\r\n        canvas.width = img.width;\r\n        canvas.height = chunkSize;\r\n\r\n        for (let i = 0; i < NUM_DATASET_ELEMENTS / chunkSize; i++) {\r\n          const datasetBytesView = new Float32Array(\r\n              datasetBytesBuffer, i * IMAGE_SIZE * chunkSize * 4,\r\n              IMAGE_SIZE * chunkSize);\r\n          ctx.drawImage(\r\n              img, 0, i * chunkSize, img.width, chunkSize, 0, 0, img.width,\r\n              chunkSize);\r\n\r\n          const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\r\n\r\n          for (let j = 0; j < imageData.data.length / 4; j++) {\r\n            // All channels hold an equal value since the image is grayscale, so\r\n            // just read the red channel.\r\n            datasetBytesView[j] = imageData.data[j * 4] / 255;\r\n          }\r\n        }\r\n        this.datasetImages = new Float32Array(datasetBytesBuffer);\r\n\r\n        resolve();\r\n      };\r\n      img.src = MNIST_IMAGES_SPRITE_PATH;\r\n    });\r\n\r\n    const labelsRequest = fetch(MNIST_LABELS_PATH);\r\n    const [imgResponse, labelsResponse] =\r\n        await Promise.all([imgRequest, labelsRequest]);\r\n\r\n    this.datasetLabels = new Uint8Array(await labelsResponse.arrayBuffer());\r\n\r\n    // Create shuffled indices into the train/test set for when we select a\r\n    // random dataset element for training / validation.\r\n    this.trainIndices = tf.util.createShuffledIndices(NUM_TRAIN_ELEMENTS);\r\n    this.testIndices = tf.util.createShuffledIndices(NUM_TEST_ELEMENTS);\r\n    // Slice the the images and labels into train and test sets.\r\n    this.trainImages =\r\n        this.datasetImages.slice(0, IMAGE_SIZE * NUM_TRAIN_ELEMENTS);\r\n    this.testImages = this.datasetImages.slice(IMAGE_SIZE * NUM_TRAIN_ELEMENTS);\r\n    this.trainLabels =\r\n        this.datasetLabels.slice(0, NUM_CLASSES * NUM_TRAIN_ELEMENTS);\r\n    this.testLabels =\r\n        this.datasetLabels.slice(NUM_CLASSES * NUM_TRAIN_ELEMENTS);\r\n  }\r\n\r\n  nextTrainBatch(batchSize) {\r\n    return this.nextBatch(\r\n        batchSize, [this.trainImages, this.trainLabels], () => {\r\n          this.shuffledTrainIndex =\r\n              (this.shuffledTrainIndex + 1) % this.trainIndices.length;\r\n          return this.trainIndices[this.shuffledTrainIndex];\r\n        });\r\n  }\r\n\r\n  nextTestBatch(batchSize) {\r\n    return this.nextBatch(batchSize, [this.testImages, this.testLabels], () => {\r\n      this.shuffledTestIndex =\r\n          (this.shuffledTestIndex + 1) % this.testIndices.length;\r\n      return this.testIndices[this.shuffledTestIndex];\r\n    });\r\n  }\r\n\r\n  nextBatch(batchSize, data, index) {\r\n    const batchImagesArray = new Float32Array(batchSize * IMAGE_SIZE);\r\n    const batchLabelsArray = new Uint8Array(batchSize * NUM_CLASSES);\r\n\r\n    for (let i = 0; i < batchSize; i++) {\r\n      const idx = index();\r\n\r\n      const image =\r\n          data[0].slice(idx * IMAGE_SIZE, idx * IMAGE_SIZE + IMAGE_SIZE);\r\n      batchImagesArray.set(image, i * IMAGE_SIZE);\r\n\r\n      const label =\r\n          data[1].slice(idx * NUM_CLASSES, idx * NUM_CLASSES + NUM_CLASSES);\r\n      batchLabelsArray.set(label, i * NUM_CLASSES);\r\n    }\r\n\r\n    const xs = tf.tensor2d(batchImagesArray, [batchSize, IMAGE_SIZE]);\r\n    const labels = tf.tensor2d(batchLabelsArray, [batchSize, NUM_CLASSES]);\r\n\r\n    return {xs, labels};\r\n  }\r\n}\r\n\r\nexport default MnistData"]}]}